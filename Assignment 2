import pandas as pd
import numpy as np


pd.set_option('display.max_columns', None)
pd.set_option('display.width', 1000)

df = pd.read_csv(r'C:\Users\Lenovo\Downloads\dataset2.csv')
print(df)


#**1. Advanced Data Cleaning (Pandas)**
#- Handle duplicate rows (keep first valid entry)
df = df.drop_duplicates(keep="first")
print(df.head())

# Fix Product typos (map variations to canonical names: ProdA/Product A → "Product A")
Product_Typo = {
    "ProdA": "Product A",
    "Product A": "Product A",
    "Item A": "Product A",
    "Prod B": "Product B",
    "Product B": "Product B",
    "Item B": "Product B",
    "PrdC": "Product C",
    "Product C": "Product C",
    "Item C": "Product C"
}

df["Product"] = df["Product"].replace(Product_Typo)

print(df.head())


#  - Replace negative Quantity with 1

df['Quantity'] = df['Quantity'].apply(lambda x: 1 if x < 0 else x)
print(df)


#- Drop rows with negative Price

df.drop(df[df['Price'] < 0].index, inplace=True)
print(df)

# - Fix Category inconsistencies (all electronics-related typos → "Electronics")
df['Category'] = df['Category'].apply(lambda x: "Electronics" if "electro" in str(x).lower() else x)
print(df)

#- Impute missing Regions using CustomerID's most common region

region = df.groupby("CustomerID")["Region"].agg(lambda x: x.mode()[0] if not x.mode().empty else "Unknown")
df["Region"] = df["Region"].fillna(df["CustomerID"].map(region))
print(df)


#- Create `IsPromo` flag from PromoCode
df["IsPromo"] = df["PromoCode"].notna().astype(int)

#- Convert all dates to UTC datetime
def convert_date(date):
    try:
        return pd.to_datetime(date, utc=True)
    except:
        try:
            return pd.to_datetime(float(date), unit='s', utc=True)
        except:
            return pd.NaT

df['OrderDate'] = df['OrderDate'].apply(convert_date)

#- Calculate order processing time (assume returns happen 7 days after order)
df["ReturnDate"] = df["OrderDate"] + pd.Timedelta(days=7)

#- Find weekly sales trends for electronics vs home goods
df["Week"] = df["OrderDate"].dt.to_period("W")
weekly_sales = df.groupby(["Week", "Category"])["Price"].sum().unstack(fill_value=0)


#- Identify customers with >2 orders in any 14-day window
df['OrderDate'] = pd.to_datetime(df['OrderDate'], errors='coerce')

df = df.sort_values(['CustomerID', 'OrderDate'])
def has_14d_window(group):
    group = group.set_index('OrderDate')
    rolling_counts = group['CustomerID'].rolling('14D').count()
    return rolling_counts.max() > 2

frequent_customers = df.groupby('CustomerID').apply(has_14d_window)
frequent_customers = frequent_customers[frequent_customers].index.tolist()

print(frequent_customers)


#- Build nested dictionary: `{CustomerID: {"total_spent": X, "favorite_category": Y}}`
Customer_Summary = df.groupby(["CustomerID", "Category"])["Price"].sum().unstack(fill_value=0)
Customer_Dict = {
    customer: {
        "total_spent": row.sum(),
        "favorite_category": row.idxmax()
    }
    for customer, row in Customer_Summary.iterrows()
}

#- Use `defaultdict` to track return rates by region: `{"North": 0.25, ...}`

from collections import defaultdict


df['ReturnFlag'] = pd.to_numeric(df['ReturnFlag'], errors='coerce')
Orders = df.groupby("Region")["ReturnFlag"].count()
Returns = df.groupby("Region")["ReturnFlag"].sum()

return_rates = defaultdict(float, (Returns / Orders).fillna(0).to_dict())

print(dict(return_rates))


#- Find most common promo code sequence using `itertools` and `Counter`
import itertools
from collections import Counter


def pairwise(iterable):
    a, b = itertools.tee(iterable)
    next(b, None)
    return zip(a, b)

sorted = df.dropna(subset=['PromoCode']).sort_values(['CustomerID', 'OrderDate'])

promo_sequences = sorted.groupby("CustomerID")["PromoCode"].apply(list)

all_bigrams = list(itertools.chain.from_iterable(
    pairwise(seq) for seq in promo_sequences if len(seq) > 1
))

common_seq, count = Counter(all_bigrams).most_common(1)[0]
print(f"Most common promo code sequence: {common_seq[0]} → {common_seq[1]} (used {count} times)")


#- Optimize memory usage by downcasting numerical columns
print( df.memory_usage(deep=True).sum(), "bytes")

for col in df.select_dtypes(include=['int64', 'float64']).columns:
    if 'int' in str(df[col].dtype):
        df[col] = pd.to_numeric(df[col], downcast='integer')
    else:
        df[col] = pd.to_numeric(df[col], downcast='float')

print( df.memory_usage(deep=True).sum(), "bytes")
